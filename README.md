# Databricks Data Pipeline Example

This repository demonstrates how to read, manipulate, engineer, and visualize data using Databricks and Apache Spark.

## Repository Structure

- **data/**: Contains the raw data files.
- **notebooks/**: Jupyter notebooks for interactive data analysis.
- **src/**: Python scripts for reading, engineering, and visualizing data.
- **images/**: Folder for images generated from visualizations.
- **README.md**: Project description and instructions.
![repo structure](https://github.com/dijasila/databricks-data-pipeline/blob/master/images/rep_struct.PNG)
## Steps

1. **Data Reading**: We use PySpark to read data from Databricks into a Spark DataFrame.
2. **Data Engineering**: Perform transformations such as filtering, grouping, and aggregating data.
3. **Data Visualization**: Visualize the engineered data using `matplotlib`.

### How to Run

1. Clone the repository:
   ```bash
   git clone https://github.com/your-username/databricks-data-pipeline.git
